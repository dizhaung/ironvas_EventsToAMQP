/*
 * #%L
 * =====================================================
 *   _____                _     ____  _   _       _   _
 *  |_   _|_ __ _   _ ___| |_  / __ \| | | | ___ | | | |
 *    | | | '__| | | / __| __|/ / _` | |_| |/ __|| |_| |
 *    | | | |  | |_| \__ \ |_| | (_| |  _  |\__ \|  _  |
 *    |_| |_|   \__,_|___/\__|\ \__,_|_| |_||___/|_| |_|
 *                             \____/
 * 
 * =====================================================
 * 
 * Hochschule Hannover
 * (University of Applied Sciences and Arts, Hannover)
 * Faculty IV, Dept. of Computer Science
 * Ricklinger Stadtweg 118, 30459 Hannover, Germany
 * 
 * Email: trust@f4-i.fh-hannover.de
 * Website: http://trust.f4.hs-hannover.de
 * 
 * This file is part of ironvas, version 0.1.7, implemented by the Trust@HsH
 * research group at the Hochschule Hannover.
 * %%
 * Copyright (C) 2011 - 2016 Trust@HsH
 * %%
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 *      http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * #L%
 */
package de.hshannover.f4.trust.ironvas;

import java.util.List;
import java.util.Set;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.logging.Logger;

import org.w3c.dom.Document;

import de.hshannover.f4.trust.ifmapj.IfmapJ;
import de.hshannover.f4.trust.ifmapj.binding.IfmapStrings;
import de.hshannover.f4.trust.ifmapj.channel.SSRC;
import de.hshannover.f4.trust.ifmapj.exception.IfmapErrorResult;
import de.hshannover.f4.trust.ifmapj.exception.IfmapException;
import de.hshannover.f4.trust.ifmapj.identifier.Device;
import de.hshannover.f4.trust.ifmapj.identifier.Identifiers;
import de.hshannover.f4.trust.ifmapj.identifier.IpAddress;
import de.hshannover.f4.trust.ifmapj.messages.PublishDelete;
import de.hshannover.f4.trust.ifmapj.messages.PublishElement;
import de.hshannover.f4.trust.ifmapj.messages.PublishRequest;
import de.hshannover.f4.trust.ifmapj.messages.PublishUpdate;
import de.hshannover.f4.trust.ifmapj.messages.Requests;
import de.hshannover.f4.trust.ifmapj.metadata.StandardIfmapMetadataFactory;
import de.hshannover.f4.trust.ironvas.converter.Converter;

/**
 * The <code>VulnerabilityHandler</code> is responsible for publishing and managing vulnerabilities.
 *
 * @author Ralf Steuerwald
 *
 */
public class VulnerabilityHandler implements Runnable {

	private static final Logger LOGGER = Logger
			.getLogger(VulnerabilityHandler.class.getName());

	private LinkedBlockingQueue<Report> mWorkQueue = new LinkedBlockingQueue<Report>();

	protected VulnerabilityCache mCache = new VulnerabilityCache();

	private SSRC mSsrc;
	private Converter mConverter;
	private String mSelfPublishDevice;
	private String mEventstream;

	private StandardIfmapMetadataFactory mMetadataFactory = IfmapJ
			.createStandardMetadataFactory();

	public VulnerabilityHandler(SSRC ifmap, Converter converter, String selfPublishDevice, String eventsream ) {
		this.mSsrc = ifmap;
		this.mConverter = converter;
		this.mSelfPublishDevice = selfPublishDevice;
		this.mEventstream = eventsream;
	}

	/**
	 * Run the handler loop. The following steps are performed:
	 * <p>
	 * 1. Wait for new vulnerabilities in the queue.<br>
	 * 2. If new vulnerabilities arrive:<br>
	 * 2.1. Check the arrived set for new vulnerabilities, not known in the cache.<br>
	 * 2.2. Check the cache for out-dated vulnerabilities.<br>
	 * 2.3. Remove the out-dated vulnerabilities from the cache.<br>
	 * 2.4. Add the new vulnerabilities to the cache.<br>
	 * 2.5. Send a publish request to the MAPS including update elements for the new and delete elements for the
	 * out-dated vulnerabilities. 3. Start at 1. again.
	 */
	@Override
	public void run() {
		LOGGER.info("starting "
				+ this.getClass().getSimpleName());

		try {
			while (!Thread.currentThread().isInterrupted()) {
				Report lastReport = mWorkQueue.take();
				onNewReport(lastReport);
			}
		} catch (InterruptedException e) {
			Thread.currentThread().interrupt();
			LOGGER.info("got interrupt signal while waiting for new work, exiting ...");
		} finally {
			LOGGER.info("shutdown complete.");
		}
	}

	public void onNewReport(Report report) {
		String taskId = report.mTaskId;

		List<Vulnerability> vulnerabilities = report.mVulnerabilities;

		Set<Vulnerability> news = mCache.indicateNew(taskId, vulnerabilities);
		Set<Vulnerability> outDated = mCache.indicateOutDated(taskId,
				vulnerabilities);

		updateCache(taskId, news, outDated);

		if (news.size() > 0
				|| outDated.size() > 0) {
			LOGGER.info(String.format(
					"publishing %d updates, %d deletes for task %s",
					news.size(), outDated.size(), report.mTaskId));
		}
		if (!mEventstream.equals("true")){ // String if it later gets a both feature
			publish(news, outDated);
		}
	}

	public void updateCache(String taskId, Set<Vulnerability> news,
			Set<Vulnerability> outDated) {
		Set<String> ipsToDelete = mCache.removeFromTask(taskId, outDated);
		Set<String> ipsToPublish = mCache.addToTask(taskId, news);
		publishAndDeleteDiscoveredBy(ipsToPublish, ipsToDelete);
	}

	public void publishAndDeleteDiscoveredBy(Set<String> ipsToPublish, Set<String> ipsToDelete) {
		PublishRequest request = Requests.createPublishReq();

		for (String ip : ipsToDelete) {
			IpAddress ipIfmap = Identifiers.createIp4(ip);
			Device devIfmap = Identifiers.createDev(mSelfPublishDevice);

			PublishDelete delete = Requests.createPublishDelete();

			String filter = String.format("meta:discovered-by[@ifmap-publisher-id='%s']",
					mSsrc.getPublisherId());

			delete.addNamespaceDeclaration("meta", IfmapStrings.STD_METADATA_NS_URI);
			delete.setFilter(filter);
			delete.setIdentifier1(ipIfmap);
			delete.setIdentifier2(devIfmap);
			request.addPublishElement(delete);
		}

		for (String ip : ipsToPublish) {
			IpAddress ipIfmap = Identifiers.createIp4(ip);
			Device devIfmap = Identifiers.createDev(mSelfPublishDevice);
			Document discoBy = mMetadataFactory.createDiscoveredBy();

			PublishUpdate update = Requests.createPublishUpdate();
			update.setIdentifier1(ipIfmap);
			update.addMetadata(discoBy);
			update.setIdentifier2(devIfmap);

			request.addPublishElement(update);
		}

		if (ipsToPublish.size() > 0
				|| ipsToDelete.size() > 0) {
			try {
				mSsrc.publish(request);
			} catch (IfmapErrorResult e) {
				LOGGER.warning("error while sending publish request "
						+ e);
			} catch (IfmapException e) {
				LOGGER.warning("error while sending publish request "
						+ e);
			}
		}
	}

	public void publish(Set<Vulnerability> news, Set<Vulnerability> outDated) {
		PublishRequest request = Requests.createPublishReq();

		if (news.size() > 0) {
			List<PublishElement> update = mConverter.toUpdates(news);
			mergeInto(update, request);
		}
		if (outDated.size() > 0) {
			List<PublishElement> delete = mConverter.toDeletes(outDated);
			mergeInto(delete, request);
		}

		if (news.size() > 0
				|| outDated.size() > 0) {
			try {
				mSsrc.publish(request);
			} catch (IfmapErrorResult e) {
				LOGGER.warning("error while sending publish request "
						+ e);
			} catch (IfmapException e) {
				LOGGER.warning("error while sending publish request "
						+ e);
			}
		}

	}

	/**
	 * Submit a list of vulnerabilities to this {@link VulnerabilityHandler}.
	 *
	 * @param lastReport
	 *            the {@link Report} containing the vulnerabilities
	 */
	public void submit(Report lastReport) {
		try {
			mWorkQueue.put(lastReport);
		} catch (InterruptedException e) {
			LOGGER.severe("could not submit vulnerabilities to handler "
					+ e.getMessage());
		}
	}

	private <T extends PublishElement> void mergeInto(List<T> elements,
			PublishRequest request) {
		for (T t : elements) {
			request.addPublishElement(t);
		}
	}

}
